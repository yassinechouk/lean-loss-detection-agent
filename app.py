"""
Application Streamlit - Dashboard interactif pour l'analyse Lean.
Point d'entrÃ©e principal : streamlit run app.py
"""
import streamlit as st
import json
from pathlib import Path
from datetime import datetime

from src.data.loader import DataLoader
from src.data.synthetic_generator import SyntheticDataGenerator
from src.agents.graph import LeanLossDetectionGraph
from src.visualization.charts import (
    create_timwoods_distribution,
    create_loss_severity_heatmap,
    create_timeline_chart,
    create_cost_impact_chart,
    create_recommendations_priority_matrix,
    create_summary_kpi_cards
)
from src.utils.config import get_settings
from src.models.schemas import AnalysisResult


# Configuration de la page
st.set_page_config(
    page_title="Agent Lean Loss Detection",
    page_icon="ğŸ­",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personnalisÃ©
st.markdown("""
<style>
    .main-title {
        font-size: 2.5rem;
        font-weight: bold;
        color: #2C3E50;
        text-align: center;
        padding: 1rem 0;
    }
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1.5rem;
        border-radius: 10px;
        color: white;
        text-align: center;
    }
    .stMetric {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
</style>
""", unsafe_allow_html=True)


def init_session_state():
    """Initialise l'Ã©tat de session Streamlit."""
    if 'analysis_result' not in st.session_state:
        st.session_state.analysis_result = None
    if 'data_loaded' not in st.session_state:
        st.session_state.data_loaded = False
    if 'analysis_running' not in st.session_state:
        st.session_state.analysis_running = False


def ensure_synthetic_data_exists():
    """GÃ©nÃ¨re les donnÃ©es synthÃ©tiques si elles n'existent pas."""
    data_dir = Path("data/synthetic")
    files_exist = (
        (data_dir / "production_logs.csv").exists() and
        (data_dir / "quality_records.csv").exists() and
        (data_dir / "incident_reports.csv").exists()
    )
    
    if not files_exist:
        with st.spinner("ğŸ”„ GÃ©nÃ©ration des donnÃ©es synthÃ©tiques..."):
            generator = SyntheticDataGenerator()
            generator.generate_all()
        st.success("âœ… DonnÃ©es synthÃ©tiques gÃ©nÃ©rÃ©es!")


def sidebar():
    """Affiche la sidebar avec les contrÃ´les."""
    st.sidebar.markdown("# ğŸ­ Lean Loss Detection")
    st.sidebar.markdown("---")
    
    # Informations sur la configuration
    settings = get_settings()
    
    st.sidebar.markdown("### âš™ï¸ Configuration")
    
    if settings.is_api_configured():
        st.sidebar.success("âœ… ClÃ© API configurÃ©e")
        st.sidebar.info(f"**ModÃ¨le** : {settings.llm_model}")
        st.sidebar.info(f"**TempÃ©rature** : {settings.llm_temperature}")
    else:
        st.sidebar.warning("âš ï¸ Pas de clÃ© API")
        st.sidebar.info("Mode heuristique activÃ©")
    
    st.sidebar.markdown("---")
    
    # Section upload de fichiers
    st.sidebar.markdown("### ğŸ“ DonnÃ©es")
    
    use_custom_data = st.sidebar.checkbox(
        "Utiliser mes propres donnÃ©es",
        value=False
    )
    
    if use_custom_data:
        st.sidebar.markdown("**Upload CSV** :")
        production_file = st.sidebar.file_uploader(
            "Production logs",
            type=['csv'],
            key="production"
        )
        quality_file = st.sidebar.file_uploader(
            "Quality records",
            type=['csv'],
            key="quality"
        )
        incident_file = st.sidebar.file_uploader(
            "Incident reports",
            type=['csv'],
            key="incident"
        )
        
        if production_file and quality_file and incident_file:
            st.sidebar.success("âœ… 3 fichiers uploadÃ©s")
        else:
            st.sidebar.info("ğŸ“¤ Uploadez les 3 fichiers CSV")
    else:
        st.sidebar.info("ğŸ“Š DonnÃ©es synthÃ©tiques")
        ensure_synthetic_data_exists()
    
    st.sidebar.markdown("---")
    
    # Bouton d'analyse
    analyze_button = st.sidebar.button(
        "ğŸš€ Lancer l'analyse",
        type="primary",
        use_container_width=True
    )
    
    st.sidebar.markdown("---")
    st.sidebar.markdown("### ğŸ“– Ã€ propos")
    st.sidebar.markdown("""
    Agent IA d'analyse Lean utilisant :
    - LangChain & LangGraph
    - Classification TIMWOODS
    - Analyse causes racines
    - Recommandations priorisÃ©es
    """)
    
    return analyze_button, use_custom_data


def load_data(use_custom_data: bool) -> dict:
    """
    Charge les donnÃ©es de production.
    
    Args:
        use_custom_data: Si True, utilise les fichiers uploadÃ©s
        
    Returns:
        Dictionnaire de donnÃ©es
    """
    if use_custom_data:
        # TODO: ImplÃ©menter le chargement des fichiers uploadÃ©s
        st.warning("âš ï¸ Chargement de fichiers custom non encore implÃ©mentÃ©. "
                  "Utilisation des donnÃ©es synthÃ©tiques.")
        use_custom_data = False
    
    if not use_custom_data:
        loader = DataLoader("data/synthetic")
        data = loader.load_all()
        return data


def run_analysis(data: dict):
    """
    ExÃ©cute l'analyse complÃ¨te.
    
    Args:
        data: DonnÃ©es de production
    """
    try:
        graph = LeanLossDetectionGraph()
        result = graph.run(data)
        st.session_state.analysis_result = result
        st.session_state.data_loaded = True
        return True
    except Exception as e:
        st.error(f"âŒ Erreur pendant l'analyse : {str(e)}")
        return False


def display_overview_tab(result: AnalysisResult):
    """Affiche l'onglet Vue d'ensemble."""
    st.markdown("## ğŸ“Š Vue d'ensemble")
    
    # KPIs
    kpis = create_summary_kpi_cards(result)
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            label="ğŸ” Pertes dÃ©tectÃ©es",
            value=kpis['total_losses'],
            delta=None
        )
    
    with col2:
        st.metric(
            label="ğŸ’° CoÃ»t estimÃ©",
            value=f"{kpis['total_cost_eur']:,.0f} â‚¬",
            delta=None
        )
    
    with col3:
        st.metric(
            label="ğŸ’¡ Recommandations",
            value=kpis['total_recommendations'],
            delta=f"{kpis['quick_wins_count']} quick wins",
            delta_color="normal"
        )
    
    with col4:
        st.metric(
            label="ğŸ“ˆ Gain potentiel",
            value=f"{kpis['potential_gain_eur']:,.0f} â‚¬",
            delta=f"ROI {kpis['roi_percentage']:.0f}%",
            delta_color="normal"
        )
    
    st.markdown("---")
    
    # Graphiques
    col1, col2 = st.columns(2)
    
    with col1:
        st.plotly_chart(
            create_timwoods_distribution(result.detected_losses),
            use_container_width=True
        )
    
    with col2:
        st.plotly_chart(
            create_timeline_chart(result.detected_losses),
            use_container_width=True
        )


def display_losses_tab(result: AnalysisResult):
    """Affiche l'onglet Pertes dÃ©tectÃ©es."""
    st.markdown("## ğŸ” Pertes dÃ©tectÃ©es")
    
    if not result.detected_losses:
        st.info("Aucune perte dÃ©tectÃ©e.")
        return
    
    # Filtres
    col1, col2, col3 = st.columns(3)
    
    with col1:
        categories = list(set(loss.timwoods_category for loss in result.detected_losses))
        selected_category = st.selectbox(
            "Filtrer par catÃ©gorie",
            ["Toutes"] + categories
        )
    
    with col2:
        severities = ["Toutes", "critical", "high", "medium", "low"]
        selected_severity = st.selectbox(
            "Filtrer par sÃ©vÃ©ritÃ©",
            severities
        )
    
    with col3:
        sort_by = st.selectbox(
            "Trier par",
            ["CoÃ»t (dÃ©croissant)", "FrÃ©quence (dÃ©croissant)", "SÃ©vÃ©ritÃ©"]
        )
    
    # Filtrer les pertes
    filtered_losses = result.detected_losses
    
    if selected_category != "Toutes":
        filtered_losses = [l for l in filtered_losses if l.timwoods_category == selected_category]
    
    if selected_severity != "Toutes":
        filtered_losses = [l for l in filtered_losses if l.severity == selected_severity]
    
    # Trier
    if sort_by == "CoÃ»t (dÃ©croissant)":
        filtered_losses = sorted(filtered_losses, key=lambda x: x.estimated_cost_eur, reverse=True)
    elif sort_by == "FrÃ©quence (dÃ©croissant)":
        filtered_losses = sorted(filtered_losses, key=lambda x: x.frequency, reverse=True)
    elif sort_by == "SÃ©vÃ©ritÃ©":
        severity_order = {"critical": 0, "high": 1, "medium": 2, "low": 3}
        filtered_losses = sorted(filtered_losses, key=lambda x: severity_order.get(x.severity, 4))
    
    st.markdown(f"**{len(filtered_losses)} perte(s) affichÃ©e(s)**")
    st.markdown("---")
    
    # Afficher les pertes
    for i, loss in enumerate(filtered_losses, 1):
        with st.expander(f"**{i}. {loss.title}** - {loss.timwoods_category} ({loss.severity.upper()})"):
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("FrÃ©quence", loss.frequency)
            with col2:
                st.metric("DurÃ©e totale", f"{loss.total_duration_hours:.1f}h")
            with col3:
                st.metric("CoÃ»t estimÃ©", f"{loss.estimated_cost_eur:,.0f} â‚¬")
            
            st.markdown("**Description :**")
            st.write(loss.description)
            
            if loss.affected_machines:
                st.markdown(f"**Machines concernÃ©es :** {', '.join(loss.affected_machines)}")
            
            if loss.affected_lines:
                st.markdown(f"**Lignes concernÃ©es :** {', '.join(loss.affected_lines)}")
            
            st.progress(loss.confidence_score)
            st.caption(f"Confiance de dÃ©tection : {loss.confidence_score:.0%}")


def display_analysis_tab(result: AnalysisResult):
    """Affiche l'onglet Analyse des causes."""
    st.markdown("## ğŸ§  Analyse des causes racines")
    
    if not result.root_cause_analyses:
        st.info("Aucune analyse de causes racines disponible.")
        return
    
    for i, rca in enumerate(result.root_cause_analyses, 1):
        # Trouver la perte correspondante
        loss = next((l for l in result.detected_losses if l.loss_id == rca.loss_id), None)
        
        if loss:
            st.markdown(f"### {i}. {loss.title}")
            st.markdown(f"**CatÃ©gorie TIMWOODS** : {loss.timwoods_category}")
            
            # Afficher les 5 Pourquoi
            st.markdown("#### ğŸ”„ MÃ©thode des 5 Pourquoi")
            
            for cause in rca.causes:
                level = cause.get('level', 0)
                cause_text = cause.get('cause', '')
                indent = "  " * (level - 1)
                st.markdown(f"{indent}**Pourquoi {level} ?** â†’ {cause_text}")
            
            st.markdown(f"**ğŸ¯ Cause racine identifiÃ©e :** {rca.root_cause}")
            
            # Facteurs contributifs
            if rca.contributing_factors:
                st.markdown("**Facteurs contributifs :**")
                for factor in rca.contributing_factors:
                    st.markdown(f"- {factor}")
            
            st.markdown("---")


def display_recommendations_tab(result: AnalysisResult):
    """Affiche l'onglet Recommandations."""
    st.markdown("## ğŸ’¡ Recommandations d'amÃ©lioration")
    
    if not result.recommendations:
        st.info("Aucune recommandation disponible.")
        return
    
    # Afficher la matrice effort/impact
    st.plotly_chart(
        create_recommendations_priority_matrix(result.recommendations),
        use_container_width=True
    )
    
    st.markdown("---")
    
    # Grouper par prioritÃ©
    st.markdown("### ğŸ“‹ Liste des recommandations")
    
    priority_labels = {1: "ğŸ”´ PrioritÃ© 1 (Haute)", 2: "ğŸŸ  PrioritÃ© 2", 
                      3: "ğŸŸ¡ PrioritÃ© 3", 4: "ğŸŸ¢ PrioritÃ© 4", 5: "âšª PrioritÃ© 5 (Basse)"}
    
    for priority in [1, 2, 3, 4, 5]:
        priority_recs = [r for r in result.recommendations if r.priority == priority]
        
        if priority_recs:
            st.markdown(f"#### {priority_labels[priority]} ({len(priority_recs)} recommandation(s))")
            
            for rec in priority_recs:
                with st.expander(f"**{rec.title}** - {rec.responsible_department}"):
                    st.markdown(rec.description)
                    
                    col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        st.metric("Gain estimÃ©", f"{rec.estimated_gain_eur:,.0f} â‚¬")
                    with col2:
                        effort_emoji = {"low": "ğŸŸ¢", "medium": "ğŸŸ¡", "high": "ğŸ”´"}
                        st.metric("Effort", f"{effort_emoji.get(rec.implementation_effort, '')} {rec.implementation_effort}")
                    with col3:
                        st.metric("Timeline", f"{rec.timeline_weeks} semaines")
                    with col4:
                        st.metric("PrioritÃ©", rec.priority)


def display_statistics_tab(result: AnalysisResult):
    """Affiche l'onglet Statistiques."""
    st.markdown("## ğŸ“ˆ Statistiques dÃ©taillÃ©es")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.plotly_chart(
            create_loss_severity_heatmap(result.detected_losses),
            use_container_width=True
        )
    
    with col2:
        st.plotly_chart(
            create_cost_impact_chart(result.detected_losses),
            use_container_width=True
        )
    
    st.markdown("---")
    
    # Statistiques rÃ©sumÃ©es
    st.markdown("### ğŸ“Š RÃ©sumÃ© statistique")
    
    stats = result.summary_stats
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("**Distribution TIMWOODS**")
        timwoods_dist = stats.get('timwoods_distribution', {})
        for category, count in sorted(timwoods_dist.items(), key=lambda x: x[1], reverse=True):
            st.write(f"{category}: {count}")
    
    with col2:
        st.markdown("**Distribution SÃ©vÃ©ritÃ©**")
        severity_dist = stats.get('severity_distribution', {})
        for severity, count in sorted(severity_dist.items(), 
                                     key=lambda x: ['critical', 'high', 'medium', 'low'].index(x[0]) if x[0] in ['critical', 'high', 'medium', 'low'] else 4):
            st.write(f"{severity.capitalize()}: {count}")
    
    with col3:
        st.markdown("**MÃ©triques clÃ©s**")
        st.write(f"CoÃ»t total: {stats.get('total_cost_eur', 0):,.0f} â‚¬")
        st.write(f"Gain potentiel: {stats.get('total_potential_gain_eur', 0):,.0f} â‚¬")
        st.write(f"ROI: {stats.get('roi_percentage', 0):.1f}%")
        st.write(f"Quick wins: {stats.get('quick_wins_count', 0)}")
    
    # Export JSON
    st.markdown("---")
    st.markdown("### ğŸ’¾ Export des rÃ©sultats")
    
    if st.button("ğŸ“¥ TÃ©lÃ©charger le rapport JSON"):
        json_data = result.model_dump_json(indent=2)
        st.download_button(
            label="TÃ©lÃ©charger JSON",
            data=json_data,
            file_name=f"lean_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            mime="application/json"
        )


def main():
    """Fonction principale de l'application."""
    init_session_state()
    
    # Titre principal
    st.markdown('<h1 class="main-title">ğŸ­ Agent IA â€“ DÃ©tection des Pertes Lean Invisibles</h1>', 
                unsafe_allow_html=True)
    
    # Sidebar
    analyze_button, use_custom_data = sidebar()
    
    # Si bouton analyse cliquÃ©
    if analyze_button:
        st.session_state.analysis_running = True
        
        with st.spinner("ğŸ”„ Chargement des donnÃ©es..."):
            data = load_data(use_custom_data)
        
        with st.spinner("ğŸ§  Analyse en cours... Cela peut prendre quelques instants."):
            success = run_analysis(data)
        
        st.session_state.analysis_running = False
        
        if success:
            st.success("âœ… Analyse terminÃ©e avec succÃ¨s!")
            st.balloons()
    
    # Affichage des rÃ©sultats
    if st.session_state.analysis_result is not None:
        result = st.session_state.analysis_result
        
        # Tabs
        tab1, tab2, tab3, tab4, tab5 = st.tabs([
            "ğŸ“Š Vue d'ensemble",
            "ğŸ” Pertes dÃ©tectÃ©es",
            "ğŸ§  Analyse des causes",
            "ğŸ’¡ Recommandations",
            "ğŸ“ˆ Statistiques"
        ])
        
        with tab1:
            display_overview_tab(result)
        
        with tab2:
            display_losses_tab(result)
        
        with tab3:
            display_analysis_tab(result)
        
        with tab4:
            display_recommendations_tab(result)
        
        with tab5:
            display_statistics_tab(result)
    
    else:
        # Message d'accueil
        st.markdown("""
        ## ğŸ‘‹ Bienvenue !
        
        Cette application utilise l'intelligence artificielle pour dÃ©tecter les **pertes Lean invisibles** 
        dans vos processus de production.
        
        ### ğŸ¯ FonctionnalitÃ©s
        
        - ğŸ” **DÃ©tection automatique** des micro-arrÃªts et pertes cachÃ©es
        - ğŸ“Š **Classification TIMWOODS** intelligente
        - ğŸ§  **Analyse de causes racines** (mÃ©thode des 5 Pourquoi)
        - ğŸ’¡ **Recommandations** d'amÃ©lioration priorisÃ©es
        - ğŸ“ˆ **Visualisations** interactives
        
        ### ğŸš€ Pour commencer
        
        1. Configurez votre clÃ© API OpenAI dans le fichier `.env` (optionnel - mode heuristique disponible)
        2. Cliquez sur **"ğŸš€ Lancer l'analyse"** dans la sidebar
        3. Explorez les rÃ©sultats dans les diffÃ©rents onglets
        
        ---
        
        ğŸ’¡ **Astuce** : Sans clÃ© API, l'application fonctionne en mode heuristique 
        avec des rÃ¨gles d'analyse basÃ©es sur des seuils statistiques.
        """)
        
        # Exemple de donnÃ©es
        with st.expander("ğŸ“Š AperÃ§u des donnÃ©es synthÃ©tiques"):
            st.markdown("""
            Les donnÃ©es synthÃ©tiques incluent :
            - **500 logs de production** sur 30 jours
            - **5 machines** (CNC-01, CNC-02, PRESS-01, PRESS-02, ASSEMBLY-01)
            - **3 lignes** de production (L1, L2, L3)
            - **200 enregistrements qualitÃ©** (rebuts, retouches, etc.)
            - **80 rapports d'incidents**
            
            **Patterns intentionnels** :
            - CNC-01 : 3x plus de micro-arrÃªts (perte cachÃ©e)
            - Shift nuit : arrÃªts plus longs
            - PRESS-01 : ralentissements rÃ©currents
            """)


if __name__ == "__main__":
    main()
